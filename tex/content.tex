\chapter{Approach}
For this simulation I created a class \texttt{Grid}, representing the lattice sites. The grid stores the orientation of each spin as well as its current momentum in a \mintinline{c++}{std::vector<double>}. Further, the site IDs of the neighbours of each site are stored in a \mintinline{c++}{std::vector<int>}.

For convenience, the class offers a constructor with a parameter \texttt{Startcondition} which is either of the constants \texttt{COLDSTART} or \texttt{HOTSTART}. That is, the grid is either initialized with all spins parallel or with completely random spins. In the further simulation I used the \texttt{COLDSTART} setting.

Further, there are accessors to the configuration vector \texttt{Q} and the momentum vector \texttt{P}. In particular I implemented an interface to use the STL \texttt{swap} method on these vectors. This allowed me to work on local copies of the grid in the simulation method that could replace the grid data without copying back the entire vector; rejecting a Markov chain point simply means doing nothing with the grid state.

Finally, the class offers a method to generate a momentum vector state with normal distribution.

The class \texttt{Grid} is a member of the class \texttt{HMC} which runs the hybrid Monte Carlo simulation on the Grid. Like in the last project, this class offers methods to read the thermodynamic properties of the associated grid state (energy density and magnetization density) as well as a method to evaluate a Hamiltonian on the grid. This Hamiltonian reads

\begin{equation}
	\Ham = \dfrac{1}{V} \left(
		 \sum_{i} \dfrac{p_i^{2}}{2m}
		 -
		 \dfrac{\beta}{2}
		 \sum_{<i, j>} \cos(q_i - q_j)
	\right)
\end{equation}

where the prefactor $\smallfrac{1}{2}$ to the potential term avoids overcounting. In the implementation, only the \emph{forward} sum is computed, \ie only the nearest neighbours in forward direction are evaluated.

Private \mintinline{c++}{std::vector<int>}s \texttt{historyE} and \texttt{historyM} store the Markov chain for a given temperature and are the basis for the computation of average energy density, magnetization density, specific heat density and magnetic susceptibility density. For these properties I adapted the methods from the last project which required only minimal changes.

The method \texttt{run} takes an \mintinline{c++}{int} parameter indicating the number of Markov chain elements. It starts by resetting the grid according to the selected \texttt{Startcondition} and clearing both the \texttt{historyX} vectors and the result member variables.

For each Markov chain point, a new momentum vector \texttt{P} is generated. Based on this, the leapfrog algorithm generates a new lattice configuration which is accepted with a probability based on the difference of the Hamiltonian of the old and the new configuration. I used a lambda function to find the first derivative wrt. time of \texttt{P} which takes one \mintinline{c++}{double} parameter indicating a half- or full time step. Updating the \texttt{Q} values takes only a simple \mintinline{c++}{for}-loop and does not justify using the same technique.

\chapter{Parameters $n_{steps}$ and $dt$}
As per usual we aim for a small number of Markov steps between independent measurements, such that the error on the estimates is as small as possible. At the same time, we would like to minimize the computation time needed to get from one configuration to the next independent configuration. This computational effort is characterized by the number $t_{indep} = 2 \tau_{int} n_{steps}$ where $n_{steps}$ is the number of leapfrog steps. Each leapfrog step corresponds to a step in time by $dt$, so we have two parameters that can influence the effort measure.

Figures \ref{fig:runtimeT1} and \ref{fig:runtimeT4} show the requirement for high and low temperatures after sampling of points in the $(n_{steps}, dt)$-plane. We see that small numbers of leapfrog steps $n_{steps}$ are generally preferable while the impact of the time stride $dt$ is of lesser import. However, time steps greater than $0.5$ lead to a high rejection rate of the Markov chain proposals.

The optimum for the low-temperature limit ($T=0.30$) was $(n, dt) = (16, 0.25)$ while for the high-temperature case ($T=4.00$) was determined to be $(n, dt) = (2, 0.6)$. Running simulations with 16 leapfrog steps takes considerable time. Also, the settings are not optimal for the high-temperature simulation. There is a zone of reasonably short time between independent configurations $t_{indep}$ around $(12, 0.25)$, so I used this setting for the entire sweep.

The plots of the $(n_{steps}, dt)$-map appear \enquote{striped}, \ie the number of leapfrog steps determines the tendency of runtime behaviour and is only amplified by certain choices of time steps. In particular for $n_{steps} = 12$ there is virtually no dependence on the parameter $dt$ for both, the high- and low-temperature scenario.

For high temperatures, longer time steps are preferable as they cause faster mutation of the lattice configuration. For cool temperatures, on the other hand, short time steps are advantageous, as the acceptance rate is much lower. Both plots cointain points rendered in white (\ie where them time between independent configurations is too large for the chosen colour map) in the $n_{steps} = 2$ column. This is due to the low mutation rate with only two leapfrog steps. However, due to the impact of the accept/reject step this occurs at different ends of the $dt$-spectrum for the high- and low-temperature case.

\begin{figure}
	\includegraphics[page=1, width=\linewidth]{./gfx/results}
	\caption{Runtime map for T=0.30} \label{fig:runtimeT1}
	\includegraphics[page=2, width=\linewidth]{./gfx/results}
	\caption{Runtime map for T=4.00} \label{fig:runtimeT4}
\end{figure}

\chapter{Results}
Figure \ref{fig:mag} plots the magnetization density vs. temperature. We see the characteristic curve we already found with the Ising model with a steep decline in magnetization around the critical temperature $T_C \approx 1$ and near-constant behaviour far from this point of phase transition.

The behaviour is mirrored in figure \ref{fig:chi} where magnetic susceptibility density is plottet against temperature. Susceptibilty starts out at a given level, peaks around the phase transition and then asymptotically approaches zero.

Errors for both, magnetization and susceptibility density are reasonably small, but become more important around the phase transition.

The maximum in magnetic susceptibility density was found at $T = 1.12$ with $\chi(1.12) = 4.33877 \pm 0.111355$ so there is only a $2.5\%$ error on the estimate. This suggests that the choice for $n_{steps}$ and $dt$ was a reasonable one.

\begin{figure}
	\includegraphics[page=4, width=\linewidth]{./gfx/results}
	\caption{Magnetization Density vs. Temperature} \label{fig:mag}
	\includegraphics[page=6, width=\linewidth]{./gfx/results}
	\caption{Magnetizatic Susceptibility Density vs. Temperature} \label{fig:chi}
\end{figure}